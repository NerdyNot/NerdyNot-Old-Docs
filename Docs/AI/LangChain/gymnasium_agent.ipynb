{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b089493",
   "metadata": {},
   "source": [
    "# 시뮬레이션 환경: Gymnasium\n",
    "\n",
    "LLM(대형 언어 모델) 에이전트의 많은 응용 프로그램에서는 환경이 실제(인터넷, 데이터베이스, REPL 등)이다. 그러나 텍스트 기반 게임과 같은 시뮬레이션된 환경에서 상호작용할 수 있는 에이전트를 정의할 수도 있다. 이 예제는 [Gymnasium](https://github.com/Farama-Foundation/Gymnasium) (이전의 [OpenAI Gym](https://github.com/openai/gym))을 사용하여 간단한 에이전트-환경 상호작용 루프를 만드는 방법을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f36427cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9bd38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tenacity\n",
    "from langchain.output_parsers import RegexParser\n",
    "from langchain.schema import (\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e222e811",
   "metadata": {},
   "source": [
    "## 에이전트 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "870c24bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GymnasiumAgent:\n",
    "    @classmethod\n",
    "    def get_docs(cls, env):\n",
    "        return env.unwrapped.__doc__\n",
    "\n",
    "    def __init__(self, model, env):\n",
    "        self.model = model\n",
    "        self.env = env\n",
    "        self.docs = self.get_docs(env)\n",
    "\n",
    "        self.instructions = \"\"\"\n",
    "당신의 목표는 당신이 받는 보상의 합계를 최대화하는 것이다.\n",
    "관찰, 보상, 종료 플래그, 자르기 플래그, 그리고 지금까지의 보상의 합계를 다음과 같은 형식으로 제공하겠다:\n",
    "\n",
    "관찰: <observation>\n",
    "보상: <reward>\n",
    "종료: <termination>\n",
    "자르기: <truncation>\n",
    "합계: <sum_of_rewards>\n",
    "\n",
    "당신은 다음과 같은 형식으로 행동을 응답해야 한다:\n",
    "\n",
    "행동: <action>\n",
    "\n",
    "여기서 <action>을 실제 행동으로 대체해야 한다.\n",
    "다른 것은 하지 말고 행동만 반환해야 한다.\n",
    "\"\"\"\n",
    "        self.action_parser = RegexParser(\n",
    "            regex=r\"Action: (.*)\", output_keys=[\"action\"], default_output_key=\"action\"\n",
    "        )\n",
    "\n",
    "        self.message_history = []\n",
    "        self.ret = 0\n",
    "\n",
    "    def random_action(self):\n",
    "        action = self.env.action_space.sample()\n",
    "        return action\n",
    "\n",
    "    def reset(self):\n",
    "        self.message_history = [\n",
    "            SystemMessage(content=self.docs),\n",
    "            SystemMessage(content=self.instructions),\n",
    "        ]\n",
    "\n",
    "    def observe(self, obs, rew=0, term=False, trunc=False, info=None):\n",
    "        self.ret += rew\n",
    "\n",
    "        obs_message = f\"\"\"\n",
    "관찰: {obs}\n",
    "보상: {rew}\n",
    "종료: {term}\n",
    "자르기: {trunc}\n",
    "합계: {self.ret}\n",
    "        \"\"\"\n",
    "        self.message_history.append(HumanMessage(content=obs_message))\n",
    "        return obs_message\n",
    "\n",
    "    def _act(self):\n",
    "        act_message = self.model.invoke(self.message_history)\n",
    "        self.message_history.append(act_message)\n",
    "        action = int(self.action_parser.parse(act_message.content)[\"action\"])\n",
    "        return action\n",
    "\n",
    "    def act(self):\n",
    "        try:\n",
    "            for attempt in tenacity.Retrying(\n",
    "                stop=tenacity.stop_after_attempt(2),\n",
    "                wait=tenacity.wait_none(),  # 재시도 간 대기 시간 없음\n",
    "                retry=tenacity.retry_if_exception_type(ValueError),\n",
    "                before_sleep=lambda retry_state: print(\n",
    "                    f\"ValueError 발생: {retry_state.outcome.exception()}, 재시도 중...\"\n",
    "                ),\n",
    "            ):\n",
    "                with attempt:\n",
    "                    action = self._act()\n",
    "        except tenacity.RetryError:\n",
    "            action = self.random_action()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e76d22c",
   "metadata": {},
   "source": [
    "## 시뮬레이션 환경 및 에이전트 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e902cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Blackjack-v1\")\n",
    "agent = GymnasiumAgent(model=ChatOpenAI(temperature=0.2), env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c12b15",
   "metadata": {},
   "source": [
    "## 메인 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad361210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "관찰: (15, 4, 0)\n",
      "보상: 0\n",
      "종료: False\n",
      "자르기: False\n",
      "합계: 0\n",
      "        \n",
      "행동: 1\n",
      "\n",
      "관찰: (25, 4, 0)\n",
      "보상: -1.0\n",
      "종료: True\n",
      "자르기: False\n",
      "합계: -1.0\n",
      "        \n",
      "break True False\n"
     ]
    }
   ],
   "source": [
    "observation, info = env.reset()\n",
    "agent.reset()\n",
    "\n",
    "obs_message = agent.observe(observation)\n",
    "print(obs_message)\n",
    "\n",
    "while True:\n",
    "    action = agent.act()\n",
    "    observation, reward, termination, truncation, info = env.step(action)\n",
    "    obs_message = agent.observe(observation, reward, termination, truncation, info)\n",
    "    print(f\"행동: {action}\")\n",
    "    print(obs_message)\n",
    "\n",
    "    if termination or truncation:\n",
    "        print(\"break\", termination, truncation)\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a13e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
