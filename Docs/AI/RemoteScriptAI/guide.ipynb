{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remote AI Script Executor with OpenAI\n",
    "\n",
    "이 Notebook은 원격 서버에서 명령을 실행하고, OpenAI 또는 Azure OpenAI를 사용하여 스크립트를 생성하는 Python 스크립트를 설명하고 테스트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 라이브러리 로드\n",
    "\n",
    "먼저 필요한 라이브러리를 로드한다. 이 스크립트는 여러 외부 라이브러리에 의존한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai paramiko pywinrm PyYAML rich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import paramiko\n",
    "import winrm\n",
    "import yaml\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.panel import Panel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OpenAI 클라이언트 설정 함수\n",
    "\n",
    "OpenAI 또는 Azure OpenAI 클라이언트를 설정하는 함수이다. YAML 구성 파일에서 API 키와 모델 정보를 읽어와 클라이언트를 초기화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_openai_client(openai_config):\n",
    "    client_type = openai_config['type'].strip().lower()\n",
    "    api_key = openai_config['api_key'].strip()\n",
    "    model = openai_config['model'].strip()\n",
    "    \n",
    "    if client_type == \"azure\":\n",
    "        azure_endpoint = openai_config['azure_endpoint'].strip()\n",
    "        azure_apiversion = openai_config['azure_apiversion'].strip()\n",
    "        os.environ['AZURE_OPENAI_API_KEY'] = api_key\n",
    "        return AzureOpenAI(\n",
    "            api_version=azure_apiversion,\n",
    "            azure_endpoint=azure_endpoint\n",
    "        ), client_type, model\n",
    "    else:\n",
    "        os.environ['OPENAI_API_KEY'] = api_key\n",
    "        return OpenAI(api_key=api_key), client_type, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 원격 Linux 서버에서 명령 실행 함수\n",
    "\n",
    "Paramiko를 사용하여 원격 Linux 서버에서 명령을 실행하는 함수이다. SSH를 통해 서버에 접속하고 명령을 실행한 후, 결과를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_remote_command_linux(host, port, username, password, command):\n",
    "    ssh = paramiko.SSHClient()\n",
    "    ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "    ssh.connect(host, port=port, username=username, password=password)\n",
    "    stdin, stdout, stderr = ssh.exec_command(command)\n",
    "    output = stdout.read().decode('utf-8') + stderr.read().decode('utf-8')\n",
    "    ssh.close()\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux 서버에서 명령 실행 테스트\n",
    "\n",
    "테스트용으로 로컬에서 작동하는 SSH 서버를 사용할 수 있다. 테스트를 위해 아래 코드를 수정하여 로컬 또는 테스트 서버의 정보를 입력하고 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test for running a command on a Linux server\n",
    "# Replace these values with your test server details\n",
    "test_host = 'your-test-host'\n",
    "test_port = 22\n",
    "test_username = 'your-username'\n",
    "test_password = 'your-password'\n",
    "test_command = 'uname -a'\n",
    "\n",
    "# Run the command and print the output\n",
    "try:\n",
    "    output = run_remote_command_linux(test_host, test_port, test_username, test_password, test_command)\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f'Failed to run command: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 원격 Windows 서버에서 명령 실행 함수\n",
    "\n",
    "pywinrm을 사용하여 원격 Windows 서버에서 명령을 실행하는 함수이다. WinRM을 통해 서버에 접속하고 명령을 실행한 후, 결과를 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_remote_command_windows(host, port, username, password, command):\n",
    "    endpoint = f'http://{host}:{port}/wsman'\n",
    "    session = winrm.Session(endpoint, auth=(username, password), transport='ntlm')\n",
    "    result = session.run_ps(command)\n",
    "    return result.std_out.decode('utf-8') + result.std_err.decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows 서버에서 명령 실행 테스트\n",
    "\n",
    "테스트용으로 로컬에서 작동하는 Windows 서버를 사용할 수 있다. 테스트를 위해 아래 코드를 수정하여 로컬 또는 테스트 서버의 정보를 입력하고 실행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example test for running a command on a Windows server\n",
    "# Replace these values with your test server details\n",
    "test_host = 'your-windows-host'\n",
    "test_port = 5985\n",
    "test_username = 'your-username'\n",
    "test_password = 'your-password'\n",
    "test_command = 'Get-Process | Select-Object -First 5'\n",
    "\n",
    "# Run the command and print the output\n",
    "try:\n",
    "    output = run_remote_command_windows(test_host, test_port, test_username, test_password, test_command)\n",
    "    print(output)\n",
    "except Exception as e:\n",
    "    print(f'Failed to run command: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 스크립트 생성 함수\n",
    "\n",
    "사용자의 입력과 시스템 정보를 기반으로 OpenAI 또는 Azure OpenAI를 사용하여 스크립트를 생성하는 함수이다. 시스템 정보와 셸 버전을 기반으로 스크립트를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(user_input, client_type, model, os_info, shell_version, os_type):\n",
    "    system_prompt = f\"\"\"\n",
    "    # Instruction\n",
    "     - You are an assistant for a {os_type} operating system with the following details\n",
    "     - You must only provide the Script, without any additional explanation or text. like description or ```bash or ```powershell or ```sh.\n",
    "     - Your responses should be informative, visually appealing, logical and actionable.\n",
    "     - Your responses should be very simple and complete.\n",
    "\n",
    "    # Script Creation Rules\n",
    "     - OS Information: {os_info}\n",
    "     - Shell Version: {shell_version}\n",
    "     - Based on the user's input, generate a script to accomplish the task.\n",
    "     - To distinguish between each server, print the hostnames on environment variables.\n",
    "    \"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\"[bold green]Generating Script...[/bold green]\"):\n",
    "        response = None\n",
    "        if client_type == \"azure\":\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                    {\"role\": \"user\", \"content\": user_input}\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
    "                    {\"role\": \"user\", \"content\": user_input}\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "\n",
    "    full_response = response.choices[0].message.content.strip()\n",
    "    # Extract script part\n",
    "    script_match = re.search(r'```(powershell|bash|zsh|sh)\\s(.*?)\\s```', full_response, re.DOTALL)\n",
    "    if script_match:\n",
    "        script = script_match.group(2).strip()\n",
    "    else:\n",
    "        script = full_response  # Use the entire response if the script is not detected\n",
    "\n",
    "    return script\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 실행 결과 설명 함수\n",
    "\n",
    "실행된 스크립트의 결과를 자연어로 설명하는 함수이다. OpenAI 또는 Azure OpenAI를 사용하여 사용자의 질문에 대한 상세한 설명을 제공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_execution_result(user_input, results, client_type, model):\n",
    "    combined_results = \"\\n\".join(results)\n",
    "    prompt = f\"\"\"\n",
    "    You need to provide a detailed explanation of the results of executing a script.\n",
    "    The user should not know that the explanation is based on the script's results.\n",
    "    ```\n",
    "    User Query: {user_input}\n",
    "    Script Execution Results: {combined_results}\n",
    "    ```\n",
    "    Refer to the script execution results to respond simply to the user's query.\n",
    "    If the query is simply to run a specific program, respond that the program has been executed.\n",
    "    Always respond in the user's language.\n",
    "    \"\"\"\n",
    "    console = Console()\n",
    "    with console.status(\"[bold green]Generating Explanation...[/bold green]\"):\n",
    "        response = None\n",
    "        if client_type == \"azure\":\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt.strip()}\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "        else:\n",
    "            response = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": prompt.strip()}\n",
    "                ],\n",
    "                temperature=1,\n",
    "                max_tokens=1024,\n",
    "                top_p=1,\n",
    "                frequency_penalty=0,\n",
    "                presence_penalty=0\n",
    "            )\n",
    "\n",
    "    explanation = response.choices[0].message.content.strip()\n",
    "    return explanation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 테스트 및 인수 설정\n",
    "\n",
    "Notebook에서 직접 인수를 설정하고 실행할 수 있도록 `main` 함수를 수정한다. 이는 `argparse` 대신 직접 인수를 제공하는 방법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 환경에서 직접 인수를 설정한다.\n",
    "config_path = 'config.yaml'  # 구성 파일 경로\n",
    "auto_approve = True  # 확인 없이 실행 여부\n",
    "selected_group = 'default'  # 서버 그룹 지정\n",
    "selected_server = None  # 단일 서버 지정\n",
    "query_command = 'uname -a'  # 실행할 명령 또는 질문\n",
    "\n",
    "# Load configuration from YAML file\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "openai_config = config['openai']\n",
    "server_groups = config['servers']\n",
    "\n",
    "# Set up the OpenAI client\n",
    "client, client_type, model = set_openai_client(openai_config)\n",
    "\n",
    "# Handle single server selection or group selection\n",
    "if selected_server:\n",
    "    all_servers = [server for group in server_groups.values() for server in group]\n",
    "    selected_server = next((server for server in all_servers if server['alias'] == selected_server), None)\n",
    "    if not selected_server:\n",
    "        console.print(\"[bold red]Invalid server selected.[/bold red]\")\n",
    "    servers = [selected_server]\n",
    "else:\n",
    "    servers = server_groups.get(selected_group, [])\n",
    "\n",
    "user_input = query_command\n",
    "linux_servers = []\n",
    "windows_servers = []\n",
    "\n",
    "for server in servers:\n",
    "    host = server['host']\n",
    "    port = server.get('port', 22 if server['os_type'] == 'Linux' else 5985)  # Default ports based on OS type\n",
    "    username = server['username']\n",
    "    password = server['password']\n",
    "    os_type = server['os_type']\n",
    "\n",
    "    if os_type == 'Linux':\n",
    "        os_info = run_remote_command_linux(host, port, username, password, \"uname -a\")\n",
    "        shell_version = run_remote_command_linux(host, port, username, password, \"echo $SHELL --version\")\n",
    "        linux_servers.append((host, port, username, password, os_info, shell_version))\n",
    "    elif os_type == 'Windows':\n",
    "        os_info = run_remote_command_windows(host, port, username, password, \"systeminfo\")\n",
    "        shell_version = run_remote_command_windows(host, port, username, password, \"$PSVersionTable.PSVersion\")\n",
    "        windows_servers.append((host, port, username, password, os_info, shell_version))\n",
    "    else:\n",
    "        console.print(f\"[bold red]Unsupported OS type: {os_type}[/bold red]\")\n",
    "\n",
    "results = []\n",
    "\n",
    "# Generate and execute script for Linux servers\n",
    "if linux_servers:\n",
    "    os_info = linux_servers[0][4]\n",
    "    shell_version = linux_servers[0][5]\n",
    "    linux_script = generate_script(user_input, client_type, model, os_info, shell_version, \"Linux\")\n",
    "    console.print(Panel(f\"[bold cyan]Generated Script for Linux servers:[/bold cyan]\\n\\n[bold]{linux_script}[/bold]\"))\n",
    "\n",
    "# Generate and execute script for Windows servers\n",
    "if windows_servers:\n",
    "    os_info = windows_servers[0][4]\n",
    "    shell_version = windows_servers[0][5]\n",
    "    windows_script = generate_script(user_input, client_type, model, os_info, shell_version, \"Windows\")\n",
    "    console.print(Panel(f\"[bold cyan]Generated Script for Windows servers:[/bold cyan]\\n\\n[bold]{windows_script}[/bold]\"))\n",
    "\n",
    "# Confirm and execute the command on all servers in the selected group\n",
    "if auto_approve or input(\"Do you want to execute this command on all servers in the selected group? (yes/y/no/n): \").strip().lower() in ['yes', 'y']:\n",
    "    for host, port, username, password, os_info, shell_version in linux_servers + windows_servers:\n",
    "        if os_info.startswith('Linux'):\n",
    "            output = run_remote_command_linux(host, port, username, password, linux_script)\n",
    "        else:\n",
    "            output = run_remote_command_windows(host, port, username, password, windows_script)\n",
    "\n",
    "        results.append(f\"Output from {host}:\\n{output}\")\n",
    "\n",
    "    if results:\n",
    "        explanation = explain_execution_result(user_input, results, client_type, model)\n",
    "\n",
    "        # Displaying combined results\n",
    "        combined_results = \"\\n\\n\".join(results)\n",
    "        console.print(Panel(f\"[bold green]Combined Command Execution Output:[/bold green]\\n\\n{combined_results}\"))\n",
    "\n",
    "        # Displaying explanation\n",
    "        md = Markdown(explanation)\n",
    "        console.print(Panel(md, title=\"[bold yellow]Explanation[/bold yellow]\"))\n",
    "else:\n",
    "    console.print(f\"[bold red]Command execution canceled.[/bold red]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드를 통해 원격 서버에서 명령을 실행하고, OpenAI 또는 Azure OpenAI를 사용하여 스크립트를 생성하고 실행 결과를 설명하는 전체 흐름을 관리할 수 있다. 각 부분은 독립적으로 테스트하고 조정할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.5"
  },
  "nbconvert_exporter": "python"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
